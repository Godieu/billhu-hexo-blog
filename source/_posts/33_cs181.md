---
title: "[Lecture Notes] CS181 Artificial Intelligence"
date: 2022-09-11 14:12:00
description: Lecture notes for Artificial intelligence, fall 2022
math: true
hide: true
categories: 
- Lecture Notes
tags:
- Lecture Notes
- math
---



# Lecture 1. Intro

## Three types of approaches

### **1. Symbolism 符号**

Representing knowledge with: **symbols and their compositions (expressions)**. 用离散符号的组合表示knowledge.

Inference and learning: manipulating symbols.

Advantages: expressive; interpretable; rigorous. 表达能力强; 可解释,人可读; 有严密数理逻辑基础

Disadvantages: hard to learn; rigid. 难以学习; 脆弱.

### **2. Connectionism 连接主义**

Representing knowledge with: **interconnected networks of simple units** (e.g. neural networks). 用大量简单计算单元的加权连接 (典型:神经网络)

Inference: follow the computation specified by the network.

Learning: optimization of connection weights.

Advantages: good performance; flexible. 表现好; 灵活

Disadvantages: black-box; data-hungry; hard to incorporate knowledge. 黑盒,人不可读,不可解释; 需大量训练数据; 难以融入先验知识

### **3. Statistical Approaches 基于统计的方法**

Representing knowledge with: probabilistic models.

Inference and learning: probabilistic inference.

Advantages: interpretable; rigorous; learnable. 可解释; 严密; 可学习.

Disadvantages: less expressive; less flexible. 表达能力不如符号; 灵活性不如连接主义.



## Course Overview

- Search
- Constraint satisfaction problems
- Game
- Propositional logic
- First-order predicate logic
- Probabilistic graphical models
- Probabilistic temporal models
- Probabilistic logics
- Markov decision processes
- Reinforcement learning
- Machine learning
- Introduction to natural language processing
- Introduction to computer vision





# Lecture 2. Search

## Search Problems

A Search problem consists of:

- A state space
- A successor function
- A start state and a goal test

**World state**: every detail of the environment

**Search state**: only the details needed for planning

{% note info %}

$b$ is the branching factor (maximum number of child nodes).

$m$ is the max depth.

$s$ is the depth of the shallowest solution.

Num of nodes: $1 + b + b^2 + \cdots = O(b^m)$

{% endnote %}

## Depth-First Search

Strategy: **expand deepest node first**.

Implementation: Fringe (a **stack**).

Time: $O(b^m)$ if $m$ is finite

Space: $O(bm)$

Not complete (unless we prevent cycles).

Not optimal.

## Breadth-First Search

Strategy: **expand shallowest node first**.

Implementation: fringe (a **queue**).

Time: $O(b^s)$.

Space: $O(b^s)$.

Complete.

Optimal only if all costs are $1$.

## Iterative Deepening

Idea: get **DFS's space advantage** with **BFS's time advantage**.

Space: $O(bm)$

Time: $O(b^s)$

## Uniform Cost Search

Strategy: **expand cheapest node first**.

Implementation: fringe (a priority queue, priority = cumulative cost).

Complete and optimal, but slow.

## Greedy Search

Strategy: **expand a node with smallest heuristic** (estimate of distance to goal)

Fast, but not optimal.

## A* search

Combine UCS with Greedy.

Optimal when heuristic is **admissable** (heuristic cost < actual cost).

Fast and optimal.







# Lecture 3. Constraint Satisfaction Problems 约束满足问题

## Two types of search problems

- Planning = standard search problems
- Identification = constraint satisfaction problems (CSPs)



## Backtracking Search 回溯搜索

Backtracking = DFS + variable-ordering + fail-on-violation

## Filtering: Forward checking

Keep track of domains for unassigned variables and cross off bad options.



## Filtering: constraint propagation



- **Node consistency (1)**: Each node has valid value.

  任何一个节点有可选值

- **Arc consistency (2)**: $X\to Y$ is **consistent** IFF for every $x$ in the tail there is some $y$ in the head which could be assigned without violating a constraint.

  $X\to Y$: 在X中随便选一个，Y仍然有得选

- **K-consistency**: For each $k$ nodes, any consistent assignment to $k-1$ can be extended to the $k^{th}$ node.

  对于任意$k$个点，不论$k-1$个点怎么选择，最后第$k$个点都有得选

- **Strong k-consistency**: also $k-1$, $k-2$, ..., $1$-consistent.



Claim: **Strong n-consistency** means we can **solve without backtracking**.





## Ordering: MRV (Min Remaining Value 最少剩余值)

Also called **Most constrainted variable**

Choose the variable with fewest legal left values in its domain

优先选择最少剩余量的选项 (选可选颜色数最少的点涂色)

## Ordering: LCV (Least Constraining Value 最少约束值)

Choose the least constraining value (variable that rules out the fewest values in the remaining values)

优先排除掉可能让邻居可选值最少的值，给相邻变量的赋值留下最大的灵活性   





## Tree-structured CSPs

Theorem: If the constraint graph has **no loops**, the CSP can be solved in $O(nd^2)$ time.

Algorithm:

1. Order: parents precede children
2. Remove backward: `for i in (n,2) removeInconsistent(Parent(Xi), i)`
3. Assign forward: `for i in (1,n) assign Xi consistently with Parent(Xi) `



## Nearly tree-structured CSPs

