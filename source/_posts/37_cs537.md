---
title: "[Lecture Notes] CS537 Intro to Operating Systems"
date: 2023-01-27 19:20:41
description: My Lecture notes for Intro to Operating Systems, Spring 2023, at UW-Madison
math: true
hide: true
categories: 
- Lecture Notes
tags:
- Lecture Notes
---

# Lec 2. Processes

## What is a process

- **Execution stream** (thread of control)
- **Process state**: everything code can affect or be affected
  - including: PC, registers, memory, opened files, opened OS resources...


**Process VS Program**

- Program: static data, code
  - global or initialized variables

- Process: dynamic instance of code + data
  - registers, stack, heap, address space, all memory that is accessible

1 copy of program can have many copies of processes.



## Virtualizing CPU

Goal: give each process the idea that it is running alone 

How to do: **share resources**

- For CPU: **time sharing** (save/restore process state)
  - reason we can do time sharing: small CPU/register state goes to memory
- For Memory: **space sharing**


## Getting good performance

**Direct execution**: run directly on hardware. OS loads program, jumps to `main`.

### Problem 
- process could do something restricted -- access another process or user file
- process could run forever -- need to stop + take control
- process could do something slow -- I/O... We want to use CPU for something else.

Solution: **Limited direct execution**. Let OS+hardware have some control.

**Problem 1: restricted operations**

### Solution: **hardware privilege levels**

user processes runs in restricted level ('unprivileged' or 'user mode')

OS runs in privileged level ('kernel level' or 'kernel mode')

**What privileges?**

- interact with devices (e.g. keyboard)
- interact with memory permissions (e.g. can access whole memory and control permissions in kernel mode)

**How does a process do IO?**

By **System call**: 

- controlled transfer into OS
- change privilege levels
- implemented via **Trap** (to control where to jump)


**How to take CPU away?** (take CPU away from a process / control how long a program can run)

Mechanism: trap to OS + registers save/restore

OS dispatch loop:

```
while (1) {
    run process A for some period
    stop A, save context
    load content of another process B
}
```

**Regain control**

Option 1: **Cooperative multitasking**: 

- Trust process to relinquish CPU 
  - automatic on syscall
  - extra syscall to `yield()`

- Benefits: no new OS mechanism
- Drawbacks: lame programmers; not responsive

Option 2: **??? multitasking**

- Guarantee OS runs periodically

- Set an alarm (timer)
  - program timer to interrupt every 3ms
  - interrupt causes trap + handler, invoke dispatch (dispatch can choose to switch process)

**Save state**

what: **register state** (including: GPR, PC, stack, frame(ebp))

where: **process control block (PCB)** (including: PID, process state, priority, register state, address space)










# Lec 3. CPU Scheduling

## Dispatcher - Switches between processes

- cooperative multitasking
- preemptive/true multitasking (has a timer)

saving state - called 'context switching'

loading state

![](37_cs537/dispatcher.jpg)

## Slow operations

I/O operations can take a long time. We should run other processes when one process is doing reading/writing files.

Idea: track **state** of processes

- **Running**: on CPU
- **Ready**: can run at any time
- **Blocked / Waiting**: Asleep, waiting for I/O.

![](37_cs537/process-3-states.jpg)

## Policy

**Workload**: set of jobs and tasks: (**arrival time**, **run time**)

**Job**: current execution of a process. Alternates between CPU and IO.

**Scheduler**: decides which ready job to run

**Metric**: measurement of scheduling quality

### Metrics

**Turnaround time** = Completion time - arrival time

**Response time** = First run time - arrival time

Starvation: a process is prevented from making process


### Policies

- **FIFO / FCFS** (First in first out / First come first serve)
  - Run jobs in the order they arrive
  - Turnaround time suffers when short jobs must wait for long jobs

- **SJF** (Shortest job first)
  - Run remaining job with shortest run time next

FIFO and SJF are **non-preemptive**: only schedule new job when prev job voluntarily relinquishes CPU

**preemptive**: schedule different jobs by taking CPU away from the running job

- **STCF** (Shortest Time-to-Completion First)
  - Always run job that will complete the quickest

- **RR** (Round Robin)
  - Idea: switch more often to reduce response time
  - RR increases turnaround time, decreases response time

The above are not IO aware (jobs hold on CPU while blocked on disk).

- **I/O aware scheduling**
  - Treat job A as separate CPU bursts. When A completes IO, another job A is ready.

- **MLFQ** (Multi level feedback queue)
  - multiple levels of round-robin
  - priority levels
  - can preempt them
  - Rules:
    - 1. If priority A > B, A runs.
    - 2. If priority A = B, A&B run in RR.
    - 3. Processes start at top priority.
    - 4. If job uses whold slice, demote process (longer time slices, lower priorities).
    - 5. CPU **Burst**: After some time period S, move all jobs to the topmost queue (avoid starvation).
    - 6. **Lottery scheduling**:
      - give processes lottery tickets
      - whoever wins runs
      - higher priority â†’ more tickets







# Lec 4. Virtualization: CPU to Memory

## Multicore scheduling

- **Single Global Queue**

  Advantages:

  - **Low response time** - new tasks can run on any CPU

  - **Global priorities** - new task can perrmpt any CPU running lower priority

  Drawbacks:

  - **Expensive communication**
  - Loss of cache locality when job moves between CPUs

- **Multi-queue Scheduling** (Per-CPU Queue)

  Give each CPU core its own ready quene.

  Tasks assigned to a CPU core when creation.

  Placement policy: **pick the core with shortest queue**

  Advantages: No cross-core migration & communication

  Drawbacks: Load imbalance

- **Per-CPU queue with migration**

  **Periodic rebalancer**: move jobs from cores with many jobs to those with a few jobs

  Run every few seconds (much less frequent as time slice) when load imbalance > 25%



## Process Creation

Two ways to create a process

### Option 1: **New process from scratch** (Windows)

Steps

- Load specified code and data into memory; Create empty call stack
- Create and initialize PCB (like context-switch)
- Put process on ready list

Advantages: no wasted work

Disadvantages: configuration complicated

### Option 2: Copy an existing process and change it appropriately (*nix)





# Lec 6. Paging - TLBs

### Paging:

- **Goal**: **eliminate** requirement that address space is **contiguous**

- Idea: divide address spaces and physical memory into fixed-sized pages.

- For each memory reference (steps):

  - 1. Extract **VPN** from **VA** (virt addr)

    2. Calculate addr of **PTE** (page table entry)

       PTE address = VPN * PTE size + PTBR (page table base register)

    3. Read **PTE** from memory

    4. Extract **PFN** (page frame num / physical page number)

    5. Build **PA** (phys addr)

    6. Read contents of **PA**

- Every instruction fetch/load/store takes 2 mem references. Slow!

- **Pros:**

  - **No external fragmentation**: any page can be placed in any phys addr
  - **Fast to allocate and free**: No need to search for suitable free space; doesn't need adjacent free space

- **Cons**:

  - **Additional memory reference**
  - **Storage for page tables may be substantial**

